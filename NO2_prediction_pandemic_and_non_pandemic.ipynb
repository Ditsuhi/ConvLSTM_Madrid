{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NO2_prediction_pandemic_and_non_pandemic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOgIRpWihgkmdvBikwaiH3u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ditsuhi/ConvLSTM_Madrid/blob/main/NO2_prediction_pandemic_and_non_pandemic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blBuJp12QhqF"
      },
      "source": [
        "\n",
        "def CalcIDWvalue(array_interpolate):\n",
        "  unknown_values = []\n",
        "  weighted_values_sum = 0.0\n",
        "  sum_of_weights = 0.0\n",
        "  sensitivity = 2\n",
        "  eps = 1e-12\n",
        "  neg_half_sens = -sensitivity/2.0\n",
        "\n",
        "  array_float = array_interpolate.astype(float)\n",
        "  knowncell_position= np.argwhere(array_float!=0)  \n",
        "  knowncell_value = array_float[array_float!=0]  \n",
        "  unknowncell_position = np.argwhere(array_float==0) \n",
        "\n",
        "  weight = (((knowncell_position[:,0][None,:]-unknowncell_position[:,0][:,None])**2 + (knowncell_position[:,1][None,:]-unknowncell_position[:,1][:,None])**2) + eps)**neg_half_sens\n",
        "  \n",
        "  unknown_values = np.sum(knowncell_value[None,:] * weight, axis=1) / np.sum(weight, axis=1)\n",
        "  array_float[array_float == 0 ] = unknown_values\n",
        "  return array_float.tolist()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPdpB-GKShUt"
      },
      "source": [
        "def calc_idw_fullData(full_data):\n",
        "  idw_list =[]\n",
        "  for item in full_data:\n",
        "    idw_list.append(CalcIDWvalue(item))\n",
        "\n",
        "  return idw_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1crxqX36Ts5D"
      },
      "source": [
        "def calculate_idw_fullData_allAttributes (df_all):\n",
        "  df_all_idw_list = []\n",
        "  for attr_numb in range(df_all.shape[2]):\n",
        "    certain_attr = df_all[:, :, attr_numb]\n",
        "    certain_attr_reshaped= certain_attr.reshape(certain_attr.shape[0], 20, 17)\n",
        "    certain_attr_reshaped_idw = calc_idw_fullData(certain_attr_reshaped)    \n",
        "    certain_attr_reshaped_idw_original_shape = np.reshape(certain_attr_reshaped_idw, (certain_attr.shape[0], 340))\n",
        "\n",
        "    df_all_idw_list.append(certain_attr_reshaped_idw_original_shape.tolist())\n",
        "  \n",
        "  \n",
        "  df_all_idw_array = np.dstack((item)for item in df_all_idw_list)\n",
        "  return df_all_idw_array\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVuqLVTRbKkn"
      },
      "source": [
        "import zipfile\n",
        "from glob import glob\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#unzip data giving the path of certain dataset\n",
        "path = '/content/Jan_Jun_2020.zip'\n",
        "# path = '/content/Jan_Jun_2019.zip'\n",
        "\n",
        "\n",
        "with zipfile.ZipFile(path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/')\n",
        "\n",
        "\n",
        "airMet = glob(\"/content/content/csvFiles/*.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7Ctm4qcddU9"
      },
      "source": [
        "#sort dataset with chronological order\n",
        "def sortingFiles(eachFile):\n",
        "    return int(eachFile) if eachFile.isdigit() else eachFile\n",
        "def natural_keys(eachFile):\n",
        "    return [sortingFiles(c) for c in re.split('(\\d+)',eachFile)]\n",
        "\n",
        "sorted_airMet= sorted(airMet, key = natural_keys)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pt3CtyxGEPuv"
      },
      "source": [
        "# df = [pd.read_csv(f, usecols=[' NO2']).values for f in sorted_airMet]\n",
        "df = [pd.read_csv(f, usecols=[' NO2', ' windSpeed', ' windDir', ' Temp', ' Humidity', ' Pressure', ' SolarRad', ' Prec']).values for f in sorted_airMet]\n",
        "\n",
        "df_all  = np.asarray(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sys58HBB7LC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-eL25wECAK1",
        "outputId": "3a70bd53-7b70-43eb-936c-cde4d4436be6"
      },
      "source": [
        "# handle outliers\n",
        "\n",
        "res = np.where(df_all[:, :, 3] < -3)\n",
        "reshum = np.where(df_all[:, :, 4] < 0)\n",
        "\n",
        "print(len(res[1]))\n",
        "print(len(reshum[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04M9KSbvCCFW"
      },
      "source": [
        "\n",
        "for i in range(len(res[0])):\n",
        "  if df_all[:, :, 3][res[0][i]][res[1][i]-1] > -3 and df_all[:, :, 3][res[0][i]][res[1][i]+1] > -3:\n",
        "    df_all[:, :, 3][res[0][i]][res[1][i]] = (df_all[:, :, 3][res[0][i]][res[1][i]-1]+df_all[:, :, 3][res[0][i]][res[1][i]+1])/2\n",
        "\n",
        "\n",
        "for i in range(len(reshum[0])):\n",
        "  if df_all[:, :, 4][reshum[0][i]][reshum[1][i]-1] >= 0 and df_all[:, :, 4][reshum[0][i]][reshum[1][i]+1] >= 0:\n",
        "    df_all[:, :, 4][reshum[0][i]][reshum[1][i]] = (df_all[:, :, 4][reshum[0][i]][reshum[1][i]-1]+df_all[:, :, 4][reshum[0][i]][reshum[1][i]+1])/2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Efv1_vsqkX92"
      },
      "source": [
        "df_all_non_prec = np.delete(df_all, 7, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSgthHIFkCno",
        "outputId": "83caa0bb-78c0-4137-bde6-9d76607bf8cb"
      },
      "source": [
        "\n",
        "idw_dataframe = calculate_idw_fullData_allAttributes (df_all_non_prec)\n",
        "not_nun = np.nan_to_num(idw_dataframe)\n",
        "round_data = np.round(not_nun, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in true_divide\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xqmvg5okqAT6"
      },
      "source": [
        " \n",
        "# split dataset to X and y (dependent and independent)\n",
        "def split_sequence(sequence, time_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequence)):\n",
        "   \n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + 12\n",
        "    \n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif end_ix+time_steps > len(sequence)-1:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "    # seq_x, seq_y = sequence[i:end_ix], sequence[end_ix: end_ix+time_steps]\n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix+time_steps]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn np.array(X), np.array(y)\n",
        " \n",
        "\n",
        " # define input sequence\n",
        "raw_seq = round_data\n",
        "\n",
        "# time_steps = 6\n",
        "time_steps = 12\n",
        "\n",
        "X, y_total = split_sequence(raw_seq, time_steps)\n",
        "#to take only NO2 from whole features as a target variable\n",
        "y =y_total[:, :, 0]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXKYD1ZQqAXp"
      },
      "source": [
        "#split data to train and test sets\n",
        "\n",
        "X_train_notNorm, X_test_notNorm, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbCaxh3OtBGA"
      },
      "source": [
        "# to normalise train data using MinMaxScaler\n",
        "number_selected_columns = 7\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1), copy = False)\n",
        "train_Normalised = X_train_notNorm.reshape(-1, 340*number_selected_columns)\n",
        "test_Normalised = X_test_notNorm.reshape(-1, 340*number_selected_columns)\n",
        "\n",
        "train_scaled = scaler.fit_transform(train_Normalised)\n",
        "test_scaled = scaler.transform(test_Normalised)\n",
        "\n",
        "X_train = train_scaled.reshape(X_train_notNorm.shape[0], X_train_notNorm.shape[1], X_train_notNorm.shape[2], X_train_notNorm.shape[3])\n",
        "X_test = test_scaled.reshape(X_test_notNorm.shape[0], X_test_notNorm.shape[1], X_test_notNorm.shape[2], X_test_notNorm.shape[3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ1aNLIDuDpm"
      },
      "source": [
        "X_train_reshaped = X_train.reshape((X_train.shape[0], X_train.shape[1], 20, 17*number_selected_columns, 1))\n",
        "y_train_reshaped = y_train.reshape((y_train.shape[0], 20, 17*number_selected_columns, 1))\n",
        "X_test_reshaped = X_test.reshape((X_test.shape[0], X_test.shape[1], 20, 17*number_selected_columns, 1))\n",
        "y_test_reshaped = y_test.reshape(y_test.shape[0], 20, 17*number_selected_columns, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHpEJ1el15JF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBAtbz1NH57x"
      },
      "source": [
        "class BlockingTimeSeriesSplit():\n",
        "    def __init__(self, n_splits):\n",
        "        self.n_splits = n_splits\n",
        "    \n",
        "    def get_n_splits(self, X, y, groups):\n",
        "        return self.n_splits\n",
        "    \n",
        "    def split(self, X, y=None, groups=None):\n",
        "        n_samples = len(X)\n",
        "        k_fold_size = n_samples // self.n_splits\n",
        "        indices = np.arange(n_samples)\n",
        "\n",
        "        margin = 0\n",
        "        for i in range(self.n_splits):\n",
        "            start = i * k_fold_size\n",
        "            stop = start + k_fold_size\n",
        "            mid = int(0.8 * (stop - start)) + start\n",
        "            yield indices[start: mid], indices[mid + margin: stop]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmY2J_-0nxye"
      },
      "source": [
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "btscv = BlockingTimeSeriesSplit(n_splits=3)\n",
        "model = KerasRegressor(build_fn=create_model, verbose=0)\n",
        "\n",
        "\n",
        "#define the grid search parameters\n",
        "\n",
        "init_mode = ['uniform', 'normal',  'glorot_normal', 'glorot_uniform']\n",
        "optimizer = ['RMSprop',  'Adam']\n",
        "kernel_size = [(3, 3), (5, 5), (7, 7), (3, 1),(5, 1), (10,1)]\n",
        "dropout_rate = [ 0.2, 0.3,  0.5],\n",
        "filters= [8, 16, 32, 64]\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5, restore_best_weights=True)\n",
        "param_grid = dict(filters=filters, dropout_rate=dropout_rate, kernel_size=kernel_size, optimizer=optimizer, init_mode=init_mode)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=btscv)\n",
        "grid_result = grid.fit(X_train_reshaped, y_train_reshaped, epochs = 20)\n",
        "\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPmckwmK1-Ds"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5c-8cee-X6u"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import ConvLSTM2D, Dropout, BatchNormalization\n",
        "from  keras.regularizers import l2\n",
        "\n",
        "\n",
        "def create_model(number_selected_columns=7, optimizer='adam', kernel_size=(5, 1), filters=filters, dropout_rate=0.2, init_mode=\"glorot_uniform\"):\n",
        "    \n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(ConvLSTM2D(input_shape=(None,  340, number_selected_columns, 1),  filters=filters, kernel_initializer=init_mode,  kernel_size=kernel_size, padding=\"same\", return_sequences=True, kernel_regularizer=l2(0.01)))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(BatchNormalization())    \n",
        "    model.add(ConvLSTM2D(filters=filters, kernel_initializer=init_mode,  kernel_size=kernel_size, padding=\"same\", return_sequences=True))\n",
        "    model.add(Dropout(dropout_rate))  \n",
        "    model.add(BatchNormalization())\n",
        "    model.add(ConvLSTM2D(filters=filters,  kernel_initializer=init_mode,  kernel_size=kernel_size, padding=\"same\", return_sequences=True))\n",
        "    model.add(Dropout(dropout_rate))   \n",
        "    model.add(BatchNormalization())\n",
        "    model.add(ConvLSTM2D(filters=filters, kernel_initializer=init_mode,  kernel_size=kernel_size, padding=\"same\", return_sequences=True))\n",
        "    model.add(Dropout(dropout_rate))    \n",
        "    model.add(BatchNormalization())          \n",
        "    model.add(ConvLSTM2D(filters=1, kernel_initializer=init_mode, kernel_size=(1, number_selected_columns), activation='relu'))\n",
        "    model.compile(optimizer=optimizer, loss='mse')\n",
        "   \n",
        "    \n",
        "    print(model.summary())\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWnUQ8Yc-h0t"
      },
      "source": [
        "mod = create_model(number_selected_columns=7, optimizer='adam', kernel_size=(5,1), filters=32 dropout_rate=0.2, init_mode=\"glorot_uniform\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sArH2WoDDhoj"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5, restore_best_weights=True)\n",
        "history = mod.fit(X_train_reshaped, y_train_reshaped,  epochs=100, verbose=2, validation_split=0.2, shuffle=False, callbacks=[es])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJ41BttGDm3Z"
      },
      "source": [
        "yhat = mod.predict(X_test_reshaped , verbose=1)\n",
        "yhat_reshaped = yhat.reshape(y_test.shape[0], 340)\n",
        "\n",
        "testScore = mean_squared_error(yhat_reshaped, y_test_reshaped, squared=False)\n",
        "print('Test Score: %.2f RMSE' % (testScore))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxAUulVJD1xP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzbKmCrUD1zp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnF4fJWzD12f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reDsiWAeD14v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wl7lWc0AD17Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}