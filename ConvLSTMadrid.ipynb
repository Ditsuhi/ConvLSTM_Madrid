{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvLSTMadrid.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP8lZi3SU6gnBKeUZ0iEHre",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ditsuhi/ConvLSTM_Madrid/blob/main/ConvLSTMadrid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZFMBuigWScK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfiqFHJjHa3G",
        "outputId": "31d9cb39-27e5-4409-9516-7048f12f388a"
      },
      "source": [
        "!pip install rarfile\n",
        "import rarfile\n",
        "\n",
        "with rarfile.RarFile('/content/drive/MyDrive/csvFiles.rar', 'r') as rar_ref:\n",
        "    rar_ref.extractall('/content/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rarfile\n",
            "  Downloading https://files.pythonhosted.org/packages/95/f4/c92fab227c7457e3b76a4096ccb655ded9deac869849cb03afbe55dfdc1e/rarfile-4.0-py3-none-any.whl\n",
            "Installing collected packages: rarfile\n",
            "Successfully installed rarfile-4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBioFL9gHmOM"
      },
      "source": [
        "from glob import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",        
        "\n",
        "\n",
        "airMet = glob(\"/content/csvFiles/*.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYl1DzOfDfll"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.regularizers import l2\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import ConvLSTM2D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import tensorflow as tf \n",
        "from numpy.random import seed\n",
        "from operator import itemgetter\n",
        "\n",
        "\n",
        "def modelarch():\n",
        "  model = keras.Sequential([keras.Input(shape=(None,  340, 2, 1)),      \n",
        "  layers.ConvLSTM2D(filters=16, kernel_size=(3, 3), padding=\"same\", return_sequences=True, kernel_regularizer=l2(0.01)),\n",
        "  layers.Dropout(0.5),\n",
        "  layers.BatchNormalization(),\n",
        "  layers.ConvLSTM2D(filters=32, kernel_size=(3, 3), padding=\"same\", return_sequences=True),\n",
        "  layers.BatchNormalization(),\n",
        "  layers.ConvLSTM2D(filters=32, kernel_size=(3, 3), padding=\"same\", return_sequences=True),\n",
        "  layers.BatchNormalization(),\n",
        "  layers.ConvLSTM2D(filters=16, kernel_size=(3, 3), padding=\"same\", return_sequences=True),\n",
        "  layers.BatchNormalization(),      \n",
        "  layers.ConvLSTM2D(filters=1, kernel_size=(1, 1), activation='relu')])\n",
        "  model.compile(optimizer=\"adam\", loss='mse')\n",
        "  return model\n",
        "\n",
        "  \n",
        "def sortingFiles(eachFile):\n",
        "    return int(eachFile) if eachFile.isdigit() else eachFile\n",
        "\n",
        "\n",
        "def natural_keys(eachFile):\n",
        "    return [ sortingFiles(c) for c in re.split('(\\d+)',eachFile)]\n",
        "\n",
        "def sortedData(data):\n",
        "  sorted_airMetTraf = sorted(data, key = natural_keys)\n",
        "  return sorted_airMetTraf \n",
        "\n",
        "def pieceData (dataComplete):\n",
        "  sorted_part = dataComplete[: 4344]\n",
        "  return sorted_part\n",
        "\n",
        "def concatAllData(sort_data): \n",
        "  indices_to_access = [1, 5]\n",
        "  # df = [pd.read_csv(f, usecols=itemgetter(*b)(a)).values for f in sortedData(sort_data)]\n",
        "  df = [pd.read_csv(f, usecols=range(1, 3)).values for f in sortedData(sort_data)]\n",
        "  df_all = np.asarray(df)\n",
        "  print(df_all.shape)\n",
        "  return df_all\n",
        "\n",
        "\n",
        "def split_sequence(data):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(data)):    \n",
        "\t\tend_ix = i + 24    \n",
        "\t\tif end_ix+24 > len(data)-1:\n",
        "\t\t\tbreak\n",
        "\t\tseq_x, seq_y = data[i:end_ix], data[end_ix+24]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "    \n",
        "\treturn np.array(X), np.array(y)\n",
        " \n",
        "\n",
        "def splitTrainTest(X, y):\n",
        "  X_train_notNorm, X_test_notNorm, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle = False)\n",
        "  return X_train_notNorm, X_test_notNorm, y_train, y_test\n",
        "\n",
        "\n",
        "def normMinMax (X_train_notNorm, X_test_notNorm):\n",
        "  scaler = MinMaxScaler(feature_range=(0, 1), copy = False)\n",
        "  train_Normalised = X_train_notNorm.reshape(-1, 340*2)\n",
        "  test_Normalised = X_test_notNorm.reshape(-1, 340*2)\n",
        "  train_scaled = scaler.fit_transform(train_Normalised)\n",
        "  test_scaled = scaler.transform(test_Normalised)\n",
        "  X_train = train_scaled.reshape(X_train_notNorm.shape[0], X_train_notNorm.shape[1], X_train_notNorm.shape[2], X_train_notNorm.shape[3])\n",
        "  X_test = test_scaled.reshape(X_test_notNorm.shape[0], X_test_notNorm.shape[1], X_test_notNorm.shape[2], X_test_notNorm.shape[3])\n",
        "  return X_train, X_test\n",
        "\n",
        "\n",
        "def reshapeData (X_train, y_train):\n",
        "  X_train_reshaped = X_train.reshape((X_train.shape[0], X_train.shape[1], 340, 2, 1))\n",
        "  y_train_reshaped = y_train.reshape((y_train.shape[0], 340, 2, 1))\n",
        "  X_test_reshaped = X_test.reshape((X_test.shape[0], X_test.shape[1], 340, 2, 1))\n",
        "  y_test_reshaped = y_test.reshape(y_test.shape[0], 340*2)\n",
        "  return X_train_reshaped, y_train_reshaped, X_test_reshaped, y_test_reshaped \n",
        "\n",
        "\n",
        "def earlystop():\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5, restore_best_weights=True)\n",
        "  return es\n",
        "\n",
        "  \n",
        "# total_testscore =[]\n",
        "# seed_value = 42\n",
        "# tf.random.set_seed(seed_value)\n",
        "# seed(seed_value)\n",
        "concatData =concatAllData(pieceData(airMet))\n",
        "X, y = split_sequence(concatData)\n",
        "X_train_notNorm, X_test_notNorm, y_train, y_test = splitTrainTest(X, y)\n",
        "X_train, X_test = normMinMax (X_train_notNorm, X_test_notNorm)\n",
        "X_train_reshaped, y_train_reshaped, X_test_reshaped, y_test_reshaped = reshapeData (X_train, y_train)\n",
        "checkpoint = ModelCheckpoint(\"{epoch:02d}-{val_loss:.2f}.hdf5\", monitor='loss', verbose=1,\n",
        "    save_best_only=True, mode='auto', save_freq = \"epoch\")\n",
        "modelarch().fit(X_train_reshaped, y_train_reshaped,  epochs=100, verbose=2, validation_split=0.1, shuffle=False, callbacks=[earlystop(), checkpoint])\n",
        "# modelarch().load_weights(\"/content/02-2424.39.hdf5\")\n",
        "yhat = modelarch(seed_value).predict(X_test_reshaped , verbose=1)\n",
        "yhats = yhat.reshape(y_test.shape[0], 340*2)\n",
        "testScore = mean_squared_error(yhats, y_test_reshaped, squared=False)\n",
        "total_testscore.append(testScore)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
